{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9_FirstNeuralNetwork_Keras_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k5VL54cwf8t",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVpx8p5awgre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2 = Sequential() # This will be our neural network. Sequential means that the output of each layer is the input for the next one.\n",
        "model_2.add(Dense(15, input_dim=num_features_train, activation='relu')) # Our network has as input the same number of features of the training set (i.e. 20 in our case).\n",
        "model.add(Dense(10, activation='relu')) # This is the second hidden layer added\n",
        "model_2.add(Dense(size_output_onehot, activation='softmax')) # The output layer has in this case the same number of dimensions as our label one-hot vectors (i.e. 4 in our case).\n",
        "print (model_2.summary()) # .summary shows an overview of our model\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # This serves to define the loss function and optimizer.\n",
        "\n",
        "history_2 = model_2.fit(X_train_norm, Y_train_onehot, epochs=150, batch_size=64) # Training of the model\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show() # Even this was not asked in the exercise, it is generally advisable to check how our model is training \n",
        "\n",
        "Y_pred_2 = model_2.predict(X_test_norm)\n",
        "preds_2 = list()\n",
        "for i in range(len(Y_pred_2)):\n",
        "    preds_2.append(np.argmax(Y_pred_2[i])) #This serves to convert the hot encoded test label vectors to labels\n",
        "\n",
        "accuracy_test_2 = accuracy_score(preds_2,Y_test_gold)\n",
        "print('The accuracy of this second model in the test set is: '+str(round(accuracy_test_2,3)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}