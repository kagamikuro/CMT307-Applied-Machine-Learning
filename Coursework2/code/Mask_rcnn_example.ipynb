{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_rcnn_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgvc3v3RuOEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Import files from Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "data_csv = '/content/drive/My Drive/data_complete.csv'\n",
        "people = os.listdir('/content/drive/My Drive/people')\n",
        "mask_rcnn_coco = '/content/drive/My Drive/mask_rcnn_coco.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpB8FMlYuQQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "\n",
        "!pip install q keras==2.2.5\n",
        "\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "%cd Mask_RCNN/\n",
        "!python setup.py install\n",
        "!pip show mask-rcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xM6jrC3uTm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.visualize import plot_precision_recall\n",
        "from mrcnn.utils import extract_bboxes\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from mrcnn.model import mold_image\n",
        "from matplotlib.patches import Rectangle\n",
        "from numpy import expand_dims\n",
        "\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5iEhQMquWu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_csv = pd.read_csv(data_csv) \n",
        "class_csv = data_csv.loc[: , \"class\"]\n",
        "filenames_csv = data_csv.loc[: , \"filename\"]\n",
        "xmin = data_csv.loc[: , \"xmin\"]\n",
        "xmax = data_csv.loc[: , \"xmax\"]\n",
        "ymin = data_csv.loc[: , \"ymin\"]\n",
        "ymax = data_csv.loc[: , \"ymax\"]\n",
        "width_csv = data_csv.loc[: , \"width\"]\n",
        "height_csv = data_csv.loc[: , \"height\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iquyBVQmuYVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class people(Dataset):\n",
        "  def load_dataset(self, dataset_dir, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"person\")\n",
        "    self.add_class(\"dataset\", 2, \"head\")\n",
        "    self.add_class(\"dataset\", 3, \"hand\")\n",
        "    self.add_class(\"dataset\", 4, \"foot\")\n",
        "\t\t# define data locations\n",
        "    images_dir = dataset_dir + '/images/'\n",
        "    annotations_dir = dataset_dir + '/annotations/'\n",
        "    counter = 1\n",
        "    for filename in listdir(images_dir):\n",
        "\t\t\t# skip all images after 150 if we are building the train set\n",
        "      if is_train and counter >= 456:\n",
        "        continue\n",
        "\t\t\t# skip all images before 150 if we are building the test/val set\n",
        "      if not is_train and counter < 456:\n",
        "        counter += 1\n",
        "        continue\n",
        "      counter += 1\n",
        "      img_path = images_dir + filename\n",
        "      ann_path = annotations_dir + filename[:-4] + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "      self.add_image('dataset', image_id=filename[:-4], path=img_path, annotation=ann_path)\n",
        "\n",
        "\n",
        "\t# extract bounding boxes \n",
        "  def extract_boxes(self, filename):\n",
        "        boxes = list()\n",
        "        clss_list = list()\n",
        "        for i, item in enumerate(filenames_csv):\n",
        "            if item[-15:-4] == filename[-15:]:\n",
        "                coors = [xmin[i], ymin[i], xmax[i], ymax[i]]\n",
        "                clss = class_csv[i]\n",
        "                width = width_csv[i]\n",
        "                height = height_csv[i]\n",
        "                boxes.append(coors)\n",
        "                clss_list.append(clss)\n",
        "        return boxes, width, height, clss_list\n",
        "\n",
        "\t# load the masks for an image\n",
        "  def load_mask(self, image_id):\n",
        "\t\t# get details of image\n",
        "        info = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "        image_name = info['id']\n",
        "\t\t# load XML\n",
        "        boxes, w, h, clss_list = self.extract_boxes(image_name)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "        class_ids = list()\n",
        "        for i in range(len(boxes)):\n",
        "            box = boxes[i]\n",
        "            row_s, row_e = box[1], box[3]\n",
        "            col_s, col_e = box[0], box[2]\n",
        "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "            class_ids.append(self.class_names.index(clss_list[i]))\n",
        "        return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\t# load an image reference\n",
        "  def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']\n",
        "\n",
        "# define a configuration for the model\n",
        "class PeopleConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"people_cfg\"\n",
        "\t# number of classes (background + people, head, hands, foot)\n",
        "\tNUM_CLASSES = 1 + 4\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 455\n",
        "\n",
        "\n",
        "# train set\n",
        "train_set = people()\n",
        "train_set.load_dataset('drive/My Drive/people', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "\n",
        "# test set\n",
        "test_set = people()\n",
        "test_set.load_dataset('drive/My Drive/people', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mhIwLkoudZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,5): \n",
        "  image_id = i\n",
        "  # load the image\n",
        "  image = train_set.load_image(image_id)\n",
        "  # load the masks and the class ids\n",
        "  mask, class_ids = train_set.load_mask(image_id)\n",
        "  # extract bounding boxes from the masks\n",
        "  bbox = extract_bboxes(mask)\n",
        "  # display image with masks and bounding boxes\n",
        "  display_instances(image, bbox, mask, class_ids, train_set.class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwLseNTIufHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PeopleConfig(Config):\n",
        "    # define the name of the configuration\n",
        "    NAME = \"std_model\"\n",
        "    # number of classes (background + kangaroo)\n",
        "    NUM_CLASSES = 1 + 4\n",
        "    # number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 455\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    LOSS_WEIGHTS = {\n",
        "        \"rpn_class_loss\": 1.,\n",
        "        \"rpn_bbox_loss\": 1.,\n",
        "        \"mrcnn_class_loss\": 1.,\n",
        "        \"mrcnn_bbox_loss\": 1.,\n",
        "        \"mrcnn_mask_loss\": 1.\n",
        "    }\n",
        "  # prepare config\n",
        "config = PeopleConfig()\n",
        "config.display()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "model.load_weights(mask_rcnn_coco, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "# train weights (output layers or 'heads')\n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=10, layers='heads')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VpagolkujJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the prediction configuration\n",
        "class PredictionConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"people_cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 4\n",
        "\t# simplify GPU config\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1\n",
        "\n",
        "def evaluate_model(dataset, model, cfg):\n",
        " APs = list()\n",
        " #precs = list()\n",
        " #recs = list()\n",
        " #overls = list()\n",
        " for image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, prec, rec, overl = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t# store\n",
        "\t\tAPs.append(AP)\n",
        "\t\t#precs.append(prec)\n",
        "\t\t#recs.append(rec)\n",
        "\t\t#overls.append(overl)\n",
        "\t# calculate the mean AP across all images\n",
        " mAP = mean(APs)\n",
        " return mAP, prec, rec, overl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy7xEzV9ulaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5,10):\n",
        "  # create config\n",
        "  cfg = PredictionConfig()\n",
        "  # define the model\n",
        "  model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
        "  # load model weights\n",
        "  model.load_weights('std_model1153151/mask_rcnn_std_model1155151_000' + str(i) + '.h5', by_name=True)\n",
        "  # evaluate model on training dataset\n",
        "  train_mAP, train_precs, train_recs, train_overls = evaluate_model(train_set, model, cfg)\n",
        "  print(\"Train mAP: %.3f\" % train_mAP)\n",
        "  # evaluate model on test dataset\n",
        "  test_mAP, test_precs, test_recs, test_overls = evaluate_model(test_set, model, cfg)\n",
        "  print(\"Test mAP: %.3f\" % test_mAP)\n",
        "  print(\" \")\n",
        "plot_precision_recall(train_mAP, train_precs, train_recs)\n",
        "plot_precision_recall(test_mAP, test_precs, test_recs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73DS50aruo-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['person', 'head', 'hand', 'foot']\n",
        "\n",
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted_2(dataset, model, cfg, image_numb):\n",
        "  # load the image and mask\n",
        "  image = dataset.load_image(image_numb)\n",
        "  mask, _ = dataset.load_mask(image_numb)\n",
        "  # convert pixel values (e.g. center)\n",
        "  scaled_image = mold_image(image, cfg)\n",
        "  # convert image into one sample\n",
        "  sample = expand_dims(scaled_image, 0)\n",
        "  # make prediction\n",
        "  yhat = model.detect(sample, verbose=0)[0]\n",
        "  # define subplot\n",
        "  #pyplot.subplot(1, 2, 1)\n",
        "  # plot raw pixel data\n",
        "  pyplot.imshow(image)\n",
        "  pyplot.title('Actual')\n",
        "  # plot masks\n",
        "  for j in range(mask.shape[2]):\n",
        "    pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "  pyplot.show()\n",
        "  # get the context for drawing boxes\n",
        "  #pyplot.subplot(1, 2, 2)\n",
        "  # plot raw pixel data\n",
        "  pyplot.imshow(image)\n",
        "  pyplot.title('Predicted')\n",
        "  ax = pyplot.gca()\n",
        "  # plot each box\n",
        "  for val, box in enumerate(yhat['rois']):\n",
        "    # get coordinates\n",
        "    y1, x1, y2, x2 = box\n",
        "    # calculate width and height of the box\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "    # create the shape\n",
        "    rect = Rectangle((x1, y1), width, height, fill=False, color='blue')\n",
        "    labelnumb = yhat[\"class_ids\"][val]\n",
        "    label = classes[labelnumb-1]\n",
        "    ax.text(x1, y1 + 8, label,color='red', size=11, backgroundcolor=\"none\")\n",
        "    # draw the box\n",
        "    ax.add_patch(rect)\n",
        "  # show the figure\n",
        "  pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXMHUbhHuq92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "model_path = 'std_model/mask_rcnn_std_model_0007.h5'\n",
        "model.load_weights(model_path, by_name=True)\n",
        "counter = 0\n",
        "i = 30\n",
        "while counter < 30:\n",
        "  #i = random.randrange(0,155)\n",
        "  i = i + 1\n",
        "  plot_actual_vs_predicted_2(test_set, model, cfg, i)\n",
        "  counter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}