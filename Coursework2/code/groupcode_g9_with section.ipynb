{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "groupcode_g9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfG8h1_s7434",
        "colab_type": "text"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNHLgx2npVHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download VOC2012 tar file\n",
        "!wget 'http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar'\n",
        "\n",
        "# Unzip the tar file VOCtrainval_11-May-2012.tar,\n",
        "!tar -xvf 'VOCtrainval_11-May-2012.tar'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ELN6CFpZh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages needed for creation of the dataset and descriptive analysis \n",
        "\n",
        "import shutil\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMUy7ldOZMs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a subset of images to use, using the images specified in trainval.txt.\n",
        "\n",
        "vocpath = 'VOCdevkit/VOC2012/'\n",
        "\n",
        "# extract the names of the images that will be used for object detection from  'VOCdevkit/VOC2012/ImageSets/Layout/trainval.txt'\n",
        "\n",
        "image_names_tv = list()\n",
        "for line in open(vocpath + 'ImageSets/Layout/trainval.txt', 'r', encoding=\"utf8\"):\n",
        "    strip_line = line.strip()\n",
        "    image_names_tv.append(strip_line[:-3])\n",
        "\n",
        "# create a new directory to store the images and annotations needed.\n",
        "%mkdir 'dataset'\n",
        "%mkdir 'dataset/images'\n",
        "%mkdir 'dataset/annotations'\n",
        "\n",
        "for item in image_names_tv:\n",
        "  shutil.copyfile(vocpath + 'JPEGImages/' + str(item) + '.jpg', 'dataset/images/' + str(item) + '.jpg')\n",
        "  shutil.copyfile(vocpath + 'Annotations/' + str(item) + '.xml', 'dataset/annotations/' + str(item) + '.xml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg0uabXypkq9",
        "colab_type": "code",
        "outputId": "19f48bee-a5f9-44e1-9692-055a036c0d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create a csv file containing all the annotations for the dataset by extracting them from the xml annotation files.\n",
        "\n",
        "def xml_to_csv(path, folder):\n",
        "    xml_list = []\n",
        "    n = 11\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for object_ in root.findall('object'):\n",
        "            for i in range(0,len(object_)):\n",
        "                for k in range(0,len(object_)):\n",
        "                    if object_[k].tag == \"name\":\n",
        "                        name = object_[k].text\n",
        "                path_name = str(path[:-n]) + folder + \"/\" + str(root.find('filename').text)\n",
        "                for size in root.iter('size'):\n",
        "                    for j in range(0,len(size)):\n",
        "                        if size[j].tag == 'height':\n",
        "                            height = int(size[j].text)\n",
        "                        elif size[j].tag == 'width':\n",
        "                            width = int(size[j].text)\n",
        "                if len(object_[i]) == 4:\n",
        "                    for j in range(0,len(object_[i])):\n",
        "                        if object_[i][j].tag == 'xmin':\n",
        "                            xmin = int(object_[i][j].text)\n",
        "                        elif object_[i][j].tag == 'xmax':\n",
        "                            xmax = int(object_[i][j].text)\n",
        "                        elif object_[i][j].tag == 'ymin':\n",
        "                            ymin = int(object_[i][j].text)\n",
        "                        elif object_[i][j].tag == 'ymax':\n",
        "                            ymax = int(object_[i][j].text)\n",
        "                    value = (path_name,width,height,name,xmin,ymin,xmax,ymax)\n",
        "                    xml_list.append(value) \n",
        "                elif len(object_[i]) == 2:\n",
        "                    for k in range(0,len(object_[i])):\n",
        "                        if object_[i][k].tag == \"name\":\n",
        "                            name = object_[i][k].text\n",
        "                        if len(object_[i][k]) == 4:\n",
        "                            for j in range(0,len(object_[i][k])):\n",
        "                                if object_[i][k][j].tag == 'xmin':\n",
        "                                    xmin = int(object_[i][k][j].text)\n",
        "                                elif object_[i][k][j].tag == 'xmax':\n",
        "                                    xmax = int(object_[i][k][j].text)\n",
        "                                elif object_[i][k][j].tag == 'ymin':\n",
        "                                    ymin = int(object_[i][k][j].text)\n",
        "                                elif object_[i][k][j].tag == 'ymax':\n",
        "                                    ymax = int(object_[i][k][j].text)\n",
        "                    value = (path_name,width,height,name,xmin,ymin,xmax,ymax)\n",
        "                    xml_list.append(value) \n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "def main():\n",
        "  image_path = os.path.join(os.getcwd(), ('dataset/annotations'))\n",
        "  folder = 'images'\n",
        "  xml_df = xml_to_csv(image_path, folder)\n",
        "  xml_df.to_csv(('data/' + folder + '_labels.csv'), index=None)\n",
        "  print('Successfully converted xml to csv.')\n",
        "\n",
        "%mkdir 'data'\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkoC-5VC8ESd",
        "colab_type": "text"
      },
      "source": [
        "## **Data Descriptive Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QND8RyuipqYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Descriptive Anlaysis:\n",
        "\n",
        "data_csv = 'data/images_labels.csv'\n",
        "data_csv = pd.read_csv(data_csv) \n",
        "\n",
        "# Create list of columns from csv file:\n",
        "\n",
        "class_csv = data_csv.loc[: , \"class\"]\n",
        "filenames_csv = data_csv.loc[: , \"filename\"]\n",
        "xmin = data_csv.loc[: , \"xmin\"]\n",
        "xmax = data_csv.loc[: , \"xmax\"]\n",
        "ymin = data_csv.loc[: , \"ymin\"]\n",
        "ymax = data_csv.loc[: , \"ymax\"]\n",
        "width_csv = data_csv.loc[: , \"width\"]\n",
        "height_csv = data_csv.loc[: , \"height\"]\n",
        "\n",
        "#Find all the different Classes and count the number of each:\n",
        "classes = list()\n",
        "for row in class_csv:\n",
        "    if row not in classes:\n",
        "        classes.append(row)\n",
        "\n",
        "count_classes = list()\n",
        "for item in classes:\n",
        "    counter = 0\n",
        "    for element in class_csv:\n",
        "        if item == element:\n",
        "            counter += 1\n",
        "    count_classes.append(counter)\n",
        "\n",
        "print('Class:  Count')\n",
        "print(\" \")\n",
        "for i in range(0,len(count_classes)): \n",
        "  print(str(classes[i]) + ' :', count_classes[i])\n",
        "\n",
        "# Outputs the labels, person, head, hand, foot, chair, sofa, diningtable and potted plant.\n",
        "\n",
        "print(\" \")\n",
        "print(\"---------------------------\")\n",
        "print(\" \")\n",
        "\n",
        "# Remove the labels for the classes, chair, sofa, diningtable and potted plant and create a new csv file.\n",
        "remove_classes_list = list()\n",
        "column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "\n",
        "for i in range(0,len(class_csv)):\n",
        "  if class_csv[i] != 'sofa' and class_csv[i] != 'diningtable' and class_csv[i] != 'chair' and class_csv[i] != 'pottedplant':\n",
        "    value = (filenames_csv[i],width_csv[i],height_csv[i],class_csv[i],xmin[i],ymin[i],xmax[i],ymax[i])\n",
        "    remove_classes_list.append(value)\n",
        "\n",
        "df = pd.DataFrame(remove_classes_list, columns=column_name)\n",
        "df.to_csv(('data/dataset_labels_1.csv'), index=None)\n",
        "\n",
        "\n",
        "# Count the number of instances of each class in the new csv file:\n",
        "\n",
        "new_data_csv = 'data/dataset_labels_1.csv'\n",
        "new_data_csv = pd.read_csv(new_data_csv) \n",
        "\n",
        "class_csv = new_data_csv.loc[: , \"class\"]\n",
        "filenames_csv = new_data_csv.loc[: , \"filename\"]\n",
        "xmin = new_data_csv.loc[: , \"xmin\"]\n",
        "xmax = new_data_csv.loc[: , \"xmax\"]\n",
        "ymin = new_data_csv.loc[: , \"ymin\"]\n",
        "ymax = new_data_csv.loc[: , \"ymax\"]\n",
        "width_csv = new_data_csv.loc[: , \"width\"]\n",
        "height_csv = new_data_csv.loc[: , \"height\"]\n",
        "\n",
        "classes = list()\n",
        "for row in class_csv:\n",
        "    if row not in classes:\n",
        "        classes.append(row)\n",
        "\n",
        "count_classes = list()\n",
        "for item in classes:\n",
        "    counter = 0\n",
        "    for element in class_csv:\n",
        "        if item == element:\n",
        "            counter += 1\n",
        "    count_classes.append(counter)\n",
        "\n",
        "print('Class:  Count')\n",
        "print(\" \")\n",
        "for i in range(0,len(count_classes)): \n",
        "  print(str(classes[i]) + ' :', count_classes[i])\n",
        "\n",
        "# Outputs the labels, person, head, hand and foot.\n",
        "\n",
        "print(\" \")\n",
        "print(\"---------------------------\")\n",
        "print(\" \")\n",
        "\n",
        "# Count the number of objects in each image:\n",
        "\n",
        "filename_list = list()\n",
        "for row in filenames_csv:\n",
        "    if row not in filename_list:\n",
        "        filename_list.append(row)\n",
        "\n",
        "count_list = list()\n",
        "for item in filename_list:\n",
        "    counter = 0\n",
        "    for i, element in enumerate(filenames_csv):\n",
        "        if item == element:\n",
        "            counter += 1\n",
        "    count_list.append(counter)\n",
        "\n",
        "# Create a csv file containing the number of objects in each image,\n",
        "\n",
        "xml_df = pd.DataFrame(count_list, columns=['count'])\n",
        "xml_df.to_csv(('data/count_objects.csv'), index=None)\n",
        "\n",
        "# Create a list of the number of images containing n objects for n in [1,47].\n",
        "\n",
        "bin_count_list = list()\n",
        "for i in range(1,50):\n",
        "    counter = 0\n",
        "    for item in count_list:\n",
        "        if i == item:\n",
        "            counter += 1\n",
        "    bin_count_list.append(counter)\n",
        "\n",
        "print('#Objects: #Images')\n",
        "print(\"\")\n",
        "for i in range(0,len(bin_count_list)): \n",
        "  print(str(i + 1) + ' :', bin_count_list[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4vufmnCpvb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_count_objects = pd.read_csv('data/count_objects.csv')\n",
        "\n",
        "# Show statistics for the number of objects per image.\n",
        "\n",
        "pd.set_option('display.width', 100)\n",
        "pd.set_option('precision', 2)\n",
        "description_count_objects = data_count_objects.describe()\n",
        "print(description_count_objects)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOLaws_tp0SP",
        "colab_type": "text"
      },
      "source": [
        "## **Implementation of Mask R-CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ju_CPejpxlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initial Setup:\n",
        "#   Download mask_rcnn_coco weights\n",
        "#   Install tensorflow version 1.15 and keras 2.2.5\n",
        "#   CloneMatterport's Mask R-CNN repository from Github.\n",
        "#   Install all necessary packages.\n",
        "\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "\n",
        "%tensorflow_version 1.15\n",
        "import tensorflow\n",
        "\n",
        "!pip install q keras==2.2.5\n",
        "\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "%cd Mask_RCNN/\n",
        "!python setup.py install\n",
        "!pip show mask-rcnn\n",
        "\n",
        "from os import listdir\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.visualize import plot_precision_recall\n",
        "from mrcnn.utils import extract_bboxes\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.utils import compute_ap_range\n",
        "from mrcnn.utils import compute_recall\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from mrcnn.model import mold_image\n",
        "from matplotlib.patches import Rectangle\n",
        "from numpy import expand_dims\n",
        "\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU1xOYArp4ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class people(Dataset):\n",
        "  def load_dataset(self, dataset_dir, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"person\")\n",
        "    self.add_class(\"dataset\", 2, \"head\")\n",
        "    self.add_class(\"dataset\", 3, \"hand\")\n",
        "    self.add_class(\"dataset\", 4, \"foot\")\n",
        "\t\t# define data locations\n",
        "    images_dir = dataset_dir + '/images/'\n",
        "    annotations_dir = dataset_dir + '/annotations/'\n",
        "    counter = 1\n",
        "    images = os.listdir(images_dir)\n",
        "    sorted_images = sorted(images)\n",
        "    for filename in sorted_images:\n",
        "\t\t\t# skip all images after 150 if we are building the train set\n",
        "      if is_train and counter >= 456:\n",
        "        continue\n",
        "\t\t\t# skip all images before 150 if we are building the test/val set\n",
        "      if not is_train and counter < 456:\n",
        "        counter += 1\n",
        "        continue\n",
        "      img_path = images_dir + filename\n",
        "      ann_path = annotations_dir + filename[:-4] + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "      self.add_image('dataset', image_id=filename[:-4], path=img_path, annotation=ann_path)\n",
        "      counter += 1\n",
        "\n",
        "\t# extract bounding boxes from 'data/dataset_labels_1.csv' file\n",
        "  def extract_boxes(self, filename):\n",
        "        boxes = list()\n",
        "        clss_list = list()\n",
        "        for i, item in enumerate(filenames_csv):\n",
        "            if item[-15:-4] == filename[-15:]:\n",
        "                coors = [xmin[i], ymin[i], xmax[i], ymax[i]]\n",
        "                clss = class_csv[i]\n",
        "                width = width_csv[i]\n",
        "                height = height_csv[i]\n",
        "                boxes.append(coors)\n",
        "                clss_list.append(clss)\n",
        "        return boxes, width, height, clss_list\n",
        "\n",
        "\t# load the masks for an image\n",
        "  def load_mask(self, image_id):\n",
        "\t\t# get details of image\n",
        "        info = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "        image_name = info['id']\n",
        "\t\t# extract: boxes, width, height and list of classes\n",
        "        boxes, w, h, clss_list = self.extract_boxes(image_name)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks from bounding boxes\n",
        "        class_ids = list()\n",
        "        for i in range(len(boxes)):\n",
        "            box = boxes[i]\n",
        "            row_s, row_e = box[1], box[3]\n",
        "            col_s, col_e = box[0], box[2]\n",
        "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "            class_ids.append(self.class_names.index(clss_list[i]))\n",
        "        return masks, asarray(class_ids, dtype='int32')\n",
        "        #return masks, boxes, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\t# load an image reference\n",
        "  def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']\n",
        "\n",
        "# define a configuration for the model\n",
        "class mrcnnConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"mask_rcnn_cfg\"\n",
        "\t# number of classes (background + people, head, hands, foot)\n",
        "\tNUM_CLASSES = 1 + 4\n",
        "\t# number of training steps per epoch, this is equal to the number of images in the Training set\n",
        "\tSTEPS_PER_EPOCH = 455\n",
        "\n",
        "# create train set\n",
        "train_set = people()\n",
        "train_set.load_dataset('dataset', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "\n",
        "# create test set\n",
        "test_set = people()\n",
        "test_set.load_dataset('dataset', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50kdnuR4p-Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optional: display some instances from the training set.\n",
        "\n",
        "for i in range(0,5): \n",
        "  image_id = i\n",
        "  # load the image\n",
        "  image = train_set.load_image(image_id)\n",
        "  # load the masks and the class ids\n",
        "  mask, class_ids = train_set.load_mask(image_id)\n",
        "  # extract bounding boxes from the masks\n",
        "  bbox = extract_bboxes(mask)\n",
        "  # display image with masks and bounding boxes\n",
        "  display_instances(image, bbox, mask, class_ids, train_set.class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an9CdAAvp_Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Training:\n",
        "\n",
        "# Create configuration for the model\n",
        "\n",
        "class mrcnnConfig(Config):\n",
        "    # define the name of the configuration\n",
        "    NAME = \"mrcnn_final_model\"\n",
        "    # number of classes (background + kangaroo)\n",
        "    NUM_CLASSES = 1 + 4\n",
        "    # number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 455\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    LEARNING_RATE = 0.005\n",
        "    LEARNING_MOMENTUM = 0.7\n",
        "    WEIGHT_DECAY = 0.00005\n",
        "    BACKBONE = 'resnet101'\n",
        "    LOSS_WEIGHTS = {\n",
        "        \"rpn_class_loss\": 1.,\n",
        "        \"rpn_bbox_loss\": 1.,\n",
        "        \"mrcnn_class_loss\": 3.5,\n",
        "        \"mrcnn_bbox_loss\": 3.5,\n",
        "        \"mrcnn_mask_loss\": 1.\n",
        "    }\n",
        "\n",
        "# Prepare config\n",
        "config = mrcnnConfig()\n",
        "config.display()\n",
        "\n",
        "# Define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# Load weights (mscoco) and exclude the output layers\n",
        "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "# Tune pre trained weights \n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=10, layers='heads')\n",
        "\n",
        "#Rename output folder of trained model checkpoints\n",
        "directory = os.listdir('/content')\n",
        "for folder in directory:\n",
        "  if folder[:17] == 'mrcnn_final_model' and folder[:-1] != 'mrcnn_final_model' and folder != 'mrcnn_final_model':\n",
        "    %mv $folder 'mrcnn_final_model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSzvIDZx8Ukt",
        "colab_type": "text"
      },
      "source": [
        "## **Model Performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHKu2puJqEtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the prediction configuration\n",
        "class PredictionConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"mrcnn_prediction_cfg\"\n",
        "\tBACKBONE = 'resnet101'\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 4\n",
        "\t# simplify GPU config\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1\n",
        "\n",
        "def evaluate_model(dataset, model, cfg):\n",
        " APs = list()\n",
        " for image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _,_,_ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\tAPs.append(AP)\n",
        " # calculate the mean AP across all images\n",
        " mAP = mean(APs)\n",
        " return mAP\n",
        "\n",
        "# create config\n",
        "cfg = PredictionConfig()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
        "\n",
        "numblist = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
        "max_test_mAP = 0\n",
        "best_epoch = 0\n",
        "for i in range(4,10):\n",
        "  # load model weights\n",
        "  model.load_weights('mrcnn_final_model/mask_rcnn_mrcnn_final_model_00' + str(numblist[i]) +'.h5', by_name=True)\n",
        "  # evaluate model on training dataset\n",
        "  train_mAP = evaluate_model(train_set, model, cfg)\n",
        "  print('Train mAP for epoch ' + str(i+1) + ' :')\n",
        "  print(\"%.3f\" % train_mAP)\n",
        "  print(\"\")\n",
        "  # evaluate model on test dataset\n",
        "  test_mAP = evaluate_model(test_set, model, cfg)\n",
        "  print('Test mAP for epoch ' + str(i+1) + ' :')\n",
        "  print(\"%.3f\" % test_mAP)\n",
        "  print(\"\")\n",
        "  if test_mAP > max_test_mAP:\n",
        "    max_test_mAP = test_mAP\n",
        "    best_epoch = i\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCYAXXfzqHwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['person', 'head', 'hand', 'foot']\n",
        "\n",
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted(dataset, model, cfg, image_numb):\n",
        "  # load the image and mask\n",
        "  image = dataset.load_image(image_numb)\n",
        "  mask, _ = dataset.load_mask(image_numb)\n",
        "  # convert pixel values (e.g. center)\n",
        "  scaled_image = mold_image(image, cfg)\n",
        "  # convert image into one sample\n",
        "  sample = expand_dims(scaled_image, 0)\n",
        "  # make prediction\n",
        "  yhat = model.detect(sample, verbose=0)[0]\n",
        "  pyplot.imshow(image)\n",
        "  pyplot.title('Actual')\n",
        "  # plot masks\n",
        "  for j in range(mask.shape[2]):\n",
        "    pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "  pyplot.show()\n",
        "  # get the context for drawing boxes\n",
        "  pyplot.imshow(image)\n",
        "  pyplot.title('Predicted')\n",
        "  ax = pyplot.gca()\n",
        "  # plot each box\n",
        "  for val, box in enumerate(yhat['rois']):\n",
        "    # get coordinates\n",
        "    y1, x1, y2, x2 = box\n",
        "    # calculate width and height of the box\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "    # create the shape\n",
        "    rect = Rectangle((x1, y1), width, height, fill=False, color='blue')\n",
        "    labelnumb = yhat[\"class_ids\"][val]\n",
        "    label = classes[labelnumb-1]\n",
        "    ax.text(x1, y1 + 10, label,color='red', size=11, backgroundcolor=\"none\")\n",
        "    # draw the box\n",
        "    ax.add_patch(rect)\n",
        "  # show the figure\n",
        "  pyplot.show()\n",
        "\n",
        "# Plot 8 random images from the test set, along with the actual and predicted bounding boxes\n",
        "\n",
        "import random\n",
        "model_path = 'mrcnn_final_model/mask_rcnn_mrcnn_final_model_00' + str(numblist[best_epoch]) + '.h5'\n",
        "model.load_weights(model_path, by_name=True)\n",
        "counter = 0\n",
        "i = 0\n",
        "while counter < 8:\n",
        "  i = random.randrange(0,155)\n",
        "  i = i + 1\n",
        "  plot_actual_vs_predicted(test_set, model, cfg, i)\n",
        "  counter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}