{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CMT307_Session12_Lab_Solutions.ipynb","provenance":[],"authorship_tag":"ABX9TyNtKmE1FsqycM/JAb2K79is"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wSMXBMOCJE1y","colab_type":"text"},"source":["**Start with the following code from the last lab session**\n","\n"," Simple image classification using CIFAR10, also provided by Keras"]},{"cell_type":"code","metadata":{"id":"lJaKa9moKucQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":397},"outputId":"fc7dc46c-5f3e-4ca4-ca48-932b9bca7a5c","executionInfo":{"status":"ok","timestamp":1582800193752,"user_tz":0,"elapsed":11171,"user":{"displayName":"Yukun Lai","photoUrl":"","userId":"08742746426457170092"}}},"source":["# Starts with imports\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# Loading dataset \n","# It is important to normalise the data\n","cifar10 = keras.datasets.cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","# Getting to know the data\n","# 50000 training images, 32*32*3 (RGB 3 channels)\n","# 10000 test images\n","# airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.\n","print(x_train.shape)\n","print(x_test.shape)\n","class_names = [\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n","# show an image\n","plt.imshow(x_train[0, ])\n","print(class_names[y_train[0][0]])\n","plt.show()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","(50000, 32, 32, 3)\n","(10000, 32, 32, 3)\n","frog\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"kbLVqTxEK6Y3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"bbce519b-7764-4d8a-9828-673ec7a0ad21","executionInfo":{"status":"ok","timestamp":1582800344717,"user_tz":0,"elapsed":148671,"user":{"displayName":"Yukun Lai","photoUrl":"","userId":"08742746426457170092"}}},"source":["# Classification with a neural network with fully connected layers\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(), metrics = [\"accuracy\"])\n","history = model.fit(x_train, y_train, epochs = 30, validation_split=0.1)\n","model.evaluate(x_test, y_test)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Train on 45000 samples, validate on 5000 samples\n","Epoch 1/30\n","45000/45000 [==============================] - 6s 136us/sample - loss: 1.9067 - acc: 0.3129 - val_loss: 2.2582 - val_acc: 0.1864\n","Epoch 2/30\n","45000/45000 [==============================] - 4s 100us/sample - loss: 1.7033 - acc: 0.3918 - val_loss: 1.6994 - val_acc: 0.3806\n","Epoch 3/30\n","45000/45000 [==============================] - 5s 102us/sample - loss: 1.6155 - acc: 0.4233 - val_loss: 1.7334 - val_acc: 0.3700\n","Epoch 4/30\n","45000/45000 [==============================] - 5s 105us/sample - loss: 1.5544 - acc: 0.4476 - val_loss: 1.6524 - val_acc: 0.4028\n","Epoch 5/30\n","45000/45000 [==============================] - 4s 100us/sample - loss: 1.5064 - acc: 0.4603 - val_loss: 1.5463 - val_acc: 0.4432\n","Epoch 6/30\n","45000/45000 [==============================] - 5s 106us/sample - loss: 1.4665 - acc: 0.4762 - val_loss: 1.5799 - val_acc: 0.4436\n","Epoch 7/30\n","45000/45000 [==============================] - 5s 101us/sample - loss: 1.4345 - acc: 0.4867 - val_loss: 1.6114 - val_acc: 0.4414\n","Epoch 8/30\n","45000/45000 [==============================] - 4s 99us/sample - loss: 1.4047 - acc: 0.4991 - val_loss: 1.5461 - val_acc: 0.4482\n","Epoch 9/30\n","45000/45000 [==============================] - 4s 99us/sample - loss: 1.3761 - acc: 0.5070 - val_loss: 1.4848 - val_acc: 0.4744\n","Epoch 10/30\n","45000/45000 [==============================] - 5s 103us/sample - loss: 1.3485 - acc: 0.5220 - val_loss: 1.5049 - val_acc: 0.4660\n","Epoch 11/30\n","45000/45000 [==============================] - 4s 97us/sample - loss: 1.3253 - acc: 0.5291 - val_loss: 1.4822 - val_acc: 0.4840\n","Epoch 12/30\n","45000/45000 [==============================] - 4s 100us/sample - loss: 1.2991 - acc: 0.5375 - val_loss: 1.4094 - val_acc: 0.5038\n","Epoch 13/30\n","45000/45000 [==============================] - 5s 100us/sample - loss: 1.2761 - acc: 0.5450 - val_loss: 1.5831 - val_acc: 0.4470\n","Epoch 14/30\n","45000/45000 [==============================] - 5s 100us/sample - loss: 1.2502 - acc: 0.5524 - val_loss: 1.4660 - val_acc: 0.4750\n","Epoch 15/30\n","45000/45000 [==============================] - 4s 98us/sample - loss: 1.2291 - acc: 0.5622 - val_loss: 1.5099 - val_acc: 0.4742\n","Epoch 16/30\n","45000/45000 [==============================] - 5s 100us/sample - loss: 1.2079 - acc: 0.5725 - val_loss: 1.4953 - val_acc: 0.4776\n","Epoch 17/30\n","45000/45000 [==============================] - 5s 102us/sample - loss: 1.1838 - acc: 0.5798 - val_loss: 1.6915 - val_acc: 0.4380\n","Epoch 18/30\n","45000/45000 [==============================] - 5s 101us/sample - loss: 1.1647 - acc: 0.5842 - val_loss: 1.4419 - val_acc: 0.4890\n","Epoch 19/30\n","45000/45000 [==============================] - 5s 106us/sample - loss: 1.1429 - acc: 0.5927 - val_loss: 1.5703 - val_acc: 0.4742\n","Epoch 20/30\n","45000/45000 [==============================] - 5s 102us/sample - loss: 1.1251 - acc: 0.6004 - val_loss: 1.3900 - val_acc: 0.5062\n","Epoch 21/30\n","45000/45000 [==============================] - 5s 102us/sample - loss: 1.1020 - acc: 0.6077 - val_loss: 1.3605 - val_acc: 0.5290\n","Epoch 22/30\n","45000/45000 [==============================] - 5s 103us/sample - loss: 1.0810 - acc: 0.6160 - val_loss: 1.4206 - val_acc: 0.5056\n","Epoch 23/30\n","45000/45000 [==============================] - 5s 105us/sample - loss: 1.0632 - acc: 0.6217 - val_loss: 1.3413 - val_acc: 0.5370\n","Epoch 24/30\n","45000/45000 [==============================] - 5s 101us/sample - loss: 1.0407 - acc: 0.6322 - val_loss: 1.6545 - val_acc: 0.4584\n","Epoch 25/30\n","45000/45000 [==============================] - 5s 102us/sample - loss: 1.0197 - acc: 0.6403 - val_loss: 1.4320 - val_acc: 0.5040\n","Epoch 26/30\n","45000/45000 [==============================] - 5s 103us/sample - loss: 0.9993 - acc: 0.6460 - val_loss: 1.5519 - val_acc: 0.4884\n","Epoch 27/30\n","45000/45000 [==============================] - 5s 103us/sample - loss: 0.9828 - acc: 0.6513 - val_loss: 1.4927 - val_acc: 0.5058\n","Epoch 28/30\n","45000/45000 [==============================] - 5s 108us/sample - loss: 0.9650 - acc: 0.6558 - val_loss: 1.4786 - val_acc: 0.5186\n","Epoch 29/30\n","45000/45000 [==============================] - 5s 104us/sample - loss: 0.9448 - acc: 0.6633 - val_loss: 1.5745 - val_acc: 0.4784\n","Epoch 30/30\n","45000/45000 [==============================] - 5s 105us/sample - loss: 0.9226 - acc: 0.6721 - val_loss: 1.6086 - val_acc: 0.4860\n","10000/10000 [==============================] - 1s 70us/sample - loss: 1.6203 - acc: 0.4813\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.6202913093566895, 0.4813]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"zu3m0vtrLJcm","colab_type":"text"},"source":["**Task 1**: Add early stopping to this. Train for up to 60 epochs, and store the model with the best performance (on the validation set)"]},{"cell_type":"code","metadata":{"id":"0HWvAaEaLU3O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":850},"outputId":"7c8087b5-87b0-4e03-fc4e-8499871f620a","executionInfo":{"status":"ok","timestamp":1582800459162,"user_tz":0,"elapsed":111958,"user":{"displayName":"Yukun Lai","photoUrl":"","userId":"08742746426457170092"}}},"source":["early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(), metrics = [\"accuracy\"])\n","history = model.fit(x_train, y_train, epochs = 60, validation_split=0.1, callbacks=[early_stopping_cb])\n","model.evaluate(x_test, y_test)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Train on 45000 samples, validate on 5000 samples\n","Epoch 1/60\n","45000/45000 [==============================] - 5s 112us/sample - loss: 1.9194 - acc: 0.3058 - val_loss: 1.9814 - val_acc: 0.2672\n","Epoch 2/60\n","45000/45000 [==============================] - 5s 107us/sample - loss: 1.7158 - acc: 0.3864 - val_loss: 1.7415 - val_acc: 0.3692\n","Epoch 3/60\n","45000/45000 [==============================] - 5s 103us/sample - loss: 1.6246 - acc: 0.4189 - val_loss: 1.5846 - val_acc: 0.4372\n","Epoch 4/60\n","45000/45000 [==============================] - 5s 105us/sample - loss: 1.5601 - acc: 0.4431 - val_loss: 1.7913 - val_acc: 0.3404\n","Epoch 5/60\n","45000/45000 [==============================] - 5s 109us/sample - loss: 1.5150 - acc: 0.4557 - val_loss: 1.5847 - val_acc: 0.4280\n","Epoch 6/60\n","45000/45000 [==============================] - 5s 104us/sample - loss: 1.4711 - acc: 0.4754 - val_loss: 1.5341 - val_acc: 0.4542\n","Epoch 7/60\n","45000/45000 [==============================] - 5s 106us/sample - loss: 1.4357 - acc: 0.4865 - val_loss: 1.6200 - val_acc: 0.4210\n","Epoch 8/60\n","45000/45000 [==============================] - 5s 102us/sample - loss: 1.4041 - acc: 0.4981 - val_loss: 1.4709 - val_acc: 0.4654\n","Epoch 9/60\n","45000/45000 [==============================] - 5s 105us/sample - loss: 1.3726 - acc: 0.5085 - val_loss: 1.5743 - val_acc: 0.4436\n","Epoch 10/60\n","45000/45000 [==============================] - 5s 106us/sample - loss: 1.3477 - acc: 0.5190 - val_loss: 1.5118 - val_acc: 0.4632\n","Epoch 11/60\n","45000/45000 [==============================] - 5s 106us/sample - loss: 1.3193 - acc: 0.5306 - val_loss: 1.4882 - val_acc: 0.4720\n","Epoch 12/60\n","45000/45000 [==============================] - 5s 114us/sample - loss: 1.2927 - acc: 0.5385 - val_loss: 1.5275 - val_acc: 0.4800\n","Epoch 13/60\n","45000/45000 [==============================] - 5s 111us/sample - loss: 1.2688 - acc: 0.5470 - val_loss: 1.4094 - val_acc: 0.5020\n","Epoch 14/60\n","45000/45000 [==============================] - 5s 107us/sample - loss: 1.2455 - acc: 0.5561 - val_loss: 1.4441 - val_acc: 0.4876\n","Epoch 15/60\n","45000/45000 [==============================] - 5s 102us/sample - loss: 1.2235 - acc: 0.5668 - val_loss: 1.4203 - val_acc: 0.4956\n","Epoch 16/60\n","45000/45000 [==============================] - 5s 107us/sample - loss: 1.2003 - acc: 0.5720 - val_loss: 1.4148 - val_acc: 0.4954\n","Epoch 17/60\n","45000/45000 [==============================] - 5s 106us/sample - loss: 1.1785 - acc: 0.5822 - val_loss: 1.6271 - val_acc: 0.4150\n","Epoch 18/60\n","45000/45000 [==============================] - 5s 109us/sample - loss: 1.1574 - acc: 0.5896 - val_loss: 1.5316 - val_acc: 0.4612\n","Epoch 19/60\n","45000/45000 [==============================] - 5s 107us/sample - loss: 1.1345 - acc: 0.5955 - val_loss: 1.6470 - val_acc: 0.4708\n","Epoch 20/60\n","45000/45000 [==============================] - 5s 106us/sample - loss: 1.1133 - acc: 0.6051 - val_loss: 1.4301 - val_acc: 0.5034\n","Epoch 21/60\n","45000/45000 [==============================] - 5s 108us/sample - loss: 1.0954 - acc: 0.6103 - val_loss: 1.6669 - val_acc: 0.4382\n","Epoch 22/60\n","45000/45000 [==============================] - 5s 103us/sample - loss: 1.0729 - acc: 0.6194 - val_loss: 1.5453 - val_acc: 0.4724\n","Epoch 23/60\n","45000/45000 [==============================] - 5s 107us/sample - loss: 1.0529 - acc: 0.6254 - val_loss: 1.4511 - val_acc: 0.5018\n","10000/10000 [==============================] - 1s 75us/sample - loss: 1.4230 - acc: 0.4982\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.4229907257080079, 0.4982]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"ZgGgqjFzLW9e","colab_type":"text"},"source":["**Task 2**: Add a Dropout layer after each layer (apart from the output layer), with dropout rate set to 0.2. \n","\n","Adjust the dropout rate and the dropout layers used and see how affects the performance."]},{"cell_type":"code","metadata":{"id":"g0CM8YdELgfm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"848adf59-490c-4f0e-d0b2-0276e51c3b40","executionInfo":{"status":"ok","timestamp":1582800803515,"user_tz":0,"elapsed":329758,"user":{"displayName":"Yukun Lai","photoUrl":"","userId":"08742746426457170092"}}},"source":["early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(300, activation=\"relu\"))   \n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(), metrics = [\"accuracy\"])\n","history = model.fit(x_train, y_train, epochs = 60, validation_split=0.1, callbacks=[early_stopping_cb])\n","model.evaluate(x_test, y_test)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Train on 45000 samples, validate on 5000 samples\n","Epoch 1/60\n","45000/45000 [==============================] - 6s 125us/sample - loss: 2.1091 - acc: 0.2119 - val_loss: 1.9475 - val_acc: 0.2828\n","Epoch 2/60\n","45000/45000 [==============================] - 6s 124us/sample - loss: 1.9246 - acc: 0.2989 - val_loss: 1.8401 - val_acc: 0.3370\n","Epoch 3/60\n","45000/45000 [==============================] - 6s 126us/sample - loss: 1.8587 - acc: 0.3264 - val_loss: 1.7630 - val_acc: 0.3696\n","Epoch 4/60\n","45000/45000 [==============================] - 6s 125us/sample - loss: 1.8100 - acc: 0.3444 - val_loss: 1.7450 - val_acc: 0.3752\n","Epoch 5/60\n","45000/45000 [==============================] - 6s 125us/sample - loss: 1.7761 - acc: 0.3569 - val_loss: 1.7045 - val_acc: 0.3874\n","Epoch 6/60\n","45000/45000 [==============================] - 6s 124us/sample - loss: 1.7485 - acc: 0.3715 - val_loss: 1.6719 - val_acc: 0.4022\n","Epoch 7/60\n","45000/45000 [==============================] - 6s 125us/sample - loss: 1.7198 - acc: 0.3838 - val_loss: 1.6425 - val_acc: 0.4194\n","Epoch 8/60\n","45000/45000 [==============================] - 6s 122us/sample - loss: 1.6959 - acc: 0.3917 - val_loss: 1.6259 - val_acc: 0.4298\n","Epoch 9/60\n","45000/45000 [==============================] - 6s 123us/sample - loss: 1.6753 - acc: 0.3979 - val_loss: 1.6058 - val_acc: 0.4308\n","Epoch 10/60\n","45000/45000 [==============================] - 6s 126us/sample - loss: 1.6589 - acc: 0.4039 - val_loss: 1.6314 - val_acc: 0.4178\n","Epoch 11/60\n","45000/45000 [==============================] - 6s 122us/sample - loss: 1.6431 - acc: 0.4087 - val_loss: 1.5864 - val_acc: 0.4356\n","Epoch 12/60\n","45000/45000 [==============================] - 6s 125us/sample - loss: 1.6259 - acc: 0.4174 - val_loss: 1.5673 - val_acc: 0.4400\n","Epoch 13/60\n","45000/45000 [==============================] - 5s 121us/sample - loss: 1.6145 - acc: 0.4208 - val_loss: 1.5564 - val_acc: 0.4460\n","Epoch 14/60\n","45000/45000 [==============================] - 6s 126us/sample - loss: 1.6016 - acc: 0.4249 - val_loss: 1.5305 - val_acc: 0.4598\n","Epoch 15/60\n","45000/45000 [==============================] - 5s 122us/sample - loss: 1.5866 - acc: 0.4320 - val_loss: 1.5755 - val_acc: 0.4482\n","Epoch 16/60\n","45000/45000 [==============================] - 6s 123us/sample - loss: 1.5755 - acc: 0.4355 - val_loss: 1.5322 - val_acc: 0.4562\n","Epoch 17/60\n","45000/45000 [==============================] - 5s 122us/sample - loss: 1.5699 - acc: 0.4361 - val_loss: 1.5003 - val_acc: 0.4724\n","Epoch 18/60\n","45000/45000 [==============================] - 5s 122us/sample - loss: 1.5533 - acc: 0.4431 - val_loss: 1.5207 - val_acc: 0.4606\n","Epoch 19/60\n","45000/45000 [==============================] - 5s 121us/sample - loss: 1.5473 - acc: 0.4460 - val_loss: 1.4922 - val_acc: 0.4628\n","Epoch 20/60\n","45000/45000 [==============================] - 6s 126us/sample - loss: 1.5373 - acc: 0.4464 - val_loss: 1.5052 - val_acc: 0.4616\n","Epoch 21/60\n","45000/45000 [==============================] - 6s 122us/sample - loss: 1.5292 - acc: 0.4524 - val_loss: 1.5023 - val_acc: 0.4678\n","Epoch 22/60\n","45000/45000 [==============================] - 6s 123us/sample - loss: 1.5204 - acc: 0.4540 - val_loss: 1.4984 - val_acc: 0.4584\n","Epoch 23/60\n","45000/45000 [==============================] - 5s 119us/sample - loss: 1.5125 - acc: 0.4560 - val_loss: 1.4509 - val_acc: 0.4878\n","Epoch 24/60\n","45000/45000 [==============================] - 6s 122us/sample - loss: 1.5037 - acc: 0.4617 - val_loss: 1.4381 - val_acc: 0.4912\n","Epoch 25/60\n","45000/45000 [==============================] - 5s 122us/sample - loss: 1.4895 - acc: 0.4666 - val_loss: 1.4435 - val_acc: 0.4844\n","Epoch 26/60\n","45000/45000 [==============================] - 5s 122us/sample - loss: 1.4877 - acc: 0.4662 - val_loss: 1.4503 - val_acc: 0.4806\n","Epoch 27/60\n","45000/45000 [==============================] - 5s 121us/sample - loss: 1.4819 - acc: 0.4679 - val_loss: 1.4083 - val_acc: 0.4968\n","Epoch 28/60\n","45000/45000 [==============================] - 5s 116us/sample - loss: 1.4740 - acc: 0.4688 - val_loss: 1.4439 - val_acc: 0.4752\n","Epoch 29/60\n","45000/45000 [==============================] - 5s 121us/sample - loss: 1.4691 - acc: 0.4708 - val_loss: 1.4376 - val_acc: 0.4906\n","Epoch 30/60\n","45000/45000 [==============================] - 5s 119us/sample - loss: 1.4613 - acc: 0.4756 - val_loss: 1.4098 - val_acc: 0.5032\n","Epoch 31/60\n","45000/45000 [==============================] - 6s 124us/sample - loss: 1.4570 - acc: 0.4780 - val_loss: 1.4517 - val_acc: 0.4928\n","Epoch 32/60\n","45000/45000 [==============================] - 6s 122us/sample - loss: 1.4504 - acc: 0.4788 - val_loss: 1.4375 - val_acc: 0.4848\n","Epoch 33/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.4464 - acc: 0.4806 - val_loss: 1.4283 - val_acc: 0.4798\n","Epoch 34/60\n","45000/45000 [==============================] - 5s 117us/sample - loss: 1.4396 - acc: 0.4825 - val_loss: 1.4097 - val_acc: 0.4956\n","Epoch 35/60\n","45000/45000 [==============================] - 5s 118us/sample - loss: 1.4328 - acc: 0.4847 - val_loss: 1.4068 - val_acc: 0.5082\n","Epoch 36/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.4279 - acc: 0.4852 - val_loss: 1.3874 - val_acc: 0.5066\n","Epoch 37/60\n","45000/45000 [==============================] - 5s 121us/sample - loss: 1.4230 - acc: 0.4904 - val_loss: 1.3836 - val_acc: 0.5000\n","Epoch 38/60\n","45000/45000 [==============================] - 5s 117us/sample - loss: 1.4165 - acc: 0.4920 - val_loss: 1.3936 - val_acc: 0.5004\n","Epoch 39/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.4084 - acc: 0.4955 - val_loss: 1.3830 - val_acc: 0.5018\n","Epoch 40/60\n","45000/45000 [==============================] - 5s 118us/sample - loss: 1.4069 - acc: 0.4949 - val_loss: 1.3595 - val_acc: 0.5132\n","Epoch 41/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.4020 - acc: 0.4963 - val_loss: 1.3537 - val_acc: 0.5212\n","Epoch 42/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.3973 - acc: 0.4989 - val_loss: 1.3596 - val_acc: 0.5146\n","Epoch 43/60\n","45000/45000 [==============================] - 5s 122us/sample - loss: 1.3940 - acc: 0.4988 - val_loss: 1.3436 - val_acc: 0.5238\n","Epoch 44/60\n","45000/45000 [==============================] - 6s 129us/sample - loss: 1.3862 - acc: 0.5032 - val_loss: 1.3471 - val_acc: 0.5230\n","Epoch 45/60\n","45000/45000 [==============================] - 5s 117us/sample - loss: 1.3833 - acc: 0.5014 - val_loss: 1.3752 - val_acc: 0.5028\n","Epoch 46/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.3767 - acc: 0.5062 - val_loss: 1.3528 - val_acc: 0.5220\n","Epoch 47/60\n","45000/45000 [==============================] - 5s 121us/sample - loss: 1.3739 - acc: 0.5074 - val_loss: 1.3631 - val_acc: 0.5132\n","Epoch 48/60\n","45000/45000 [==============================] - 5s 121us/sample - loss: 1.3676 - acc: 0.5097 - val_loss: 1.3269 - val_acc: 0.5340\n","Epoch 49/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.3636 - acc: 0.5106 - val_loss: 1.3470 - val_acc: 0.5148\n","Epoch 50/60\n","45000/45000 [==============================] - 5s 116us/sample - loss: 1.3602 - acc: 0.5103 - val_loss: 1.3471 - val_acc: 0.5162\n","Epoch 51/60\n","45000/45000 [==============================] - 5s 118us/sample - loss: 1.3520 - acc: 0.5128 - val_loss: 1.3294 - val_acc: 0.5362\n","Epoch 52/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.3536 - acc: 0.5130 - val_loss: 1.3281 - val_acc: 0.5202\n","Epoch 53/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.3500 - acc: 0.5141 - val_loss: 1.3502 - val_acc: 0.5212\n","Epoch 54/60\n","45000/45000 [==============================] - 5s 119us/sample - loss: 1.3469 - acc: 0.5144 - val_loss: 1.3378 - val_acc: 0.5270\n","Epoch 55/60\n","45000/45000 [==============================] - 6s 124us/sample - loss: 1.3416 - acc: 0.5175 - val_loss: 1.3268 - val_acc: 0.5338\n","Epoch 56/60\n","45000/45000 [==============================] - 5s 116us/sample - loss: 1.3329 - acc: 0.5176 - val_loss: 1.3299 - val_acc: 0.5292\n","Epoch 57/60\n","45000/45000 [==============================] - 5s 117us/sample - loss: 1.3286 - acc: 0.5210 - val_loss: 1.3390 - val_acc: 0.5274\n","Epoch 58/60\n","45000/45000 [==============================] - 6s 124us/sample - loss: 1.3273 - acc: 0.5202 - val_loss: 1.3307 - val_acc: 0.5216\n","Epoch 59/60\n","45000/45000 [==============================] - 5s 117us/sample - loss: 1.3267 - acc: 0.5269 - val_loss: 1.3146 - val_acc: 0.5354\n","Epoch 60/60\n","45000/45000 [==============================] - 5s 120us/sample - loss: 1.3178 - acc: 0.5263 - val_loss: 1.2993 - val_acc: 0.5412\n","10000/10000 [==============================] - 1s 72us/sample - loss: 1.3062 - acc: 0.5361\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.3061614967346191, 0.5361]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"Y1auuTrVLhFm","colab_type":"text"},"source":["**Task 3**: Build a Convolutional Neural Network using an architecture similar to the example shown in the lecture demo\n","\n","Explore different combinations of kernel sizes, and conv/pooling layers."]},{"cell_type":"code","metadata":{"id":"wo7HVgb_LpT4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"61bfd3e4-e3c2-4f59-9a04-a286efd2a801","executionInfo":{"status":"ok","timestamp":1582801417692,"user_tz":0,"elapsed":442864,"user":{"displayName":"Yukun Lai","photoUrl":"","userId":"08742746426457170092"}}},"source":["early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n","model = keras.models.Sequential([\n","    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n","                        input_shape=[32, 32, 3]),\n","    keras.layers.MaxPooling2D(2),\n","    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n","    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n","    keras.layers.MaxPooling2D(2),\n","    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n","    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n","    keras.layers.MaxPooling2D(2),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(128, activation=\"relu\"),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(64, activation=\"relu\"),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(10, activation=\"softmax\")\n","])\n","model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics = [\"accuracy\"])\n","history = model.fit(x_train, y_train, epochs = 60, validation_split=0.1, callbacks=[early_stopping_cb])\n","model.evaluate(x_test, y_test)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Train on 45000 samples, validate on 5000 samples\n","Epoch 1/60\n","45000/45000 [==============================] - 20s 442us/sample - loss: 2.2212 - acc: 0.1587 - val_loss: 2.0323 - val_acc: 0.2682\n","Epoch 2/60\n","45000/45000 [==============================] - 15s 332us/sample - loss: 2.0108 - acc: 0.2522 - val_loss: 1.8393 - val_acc: 0.3224\n","Epoch 3/60\n","45000/45000 [==============================] - 15s 335us/sample - loss: 1.8433 - acc: 0.3129 - val_loss: 1.6761 - val_acc: 0.3914\n","Epoch 4/60\n","45000/45000 [==============================] - 15s 336us/sample - loss: 1.7144 - acc: 0.3674 - val_loss: 1.6448 - val_acc: 0.4162\n","Epoch 5/60\n","45000/45000 [==============================] - 15s 332us/sample - loss: 1.6169 - acc: 0.4103 - val_loss: 1.4272 - val_acc: 0.4840\n","Epoch 6/60\n","45000/45000 [==============================] - 15s 332us/sample - loss: 1.5460 - acc: 0.4392 - val_loss: 1.3410 - val_acc: 0.5082\n","Epoch 7/60\n","45000/45000 [==============================] - 15s 335us/sample - loss: 1.4779 - acc: 0.4704 - val_loss: 1.3615 - val_acc: 0.5140\n","Epoch 8/60\n","45000/45000 [==============================] - 15s 334us/sample - loss: 1.4096 - acc: 0.4962 - val_loss: 1.3291 - val_acc: 0.5070\n","Epoch 9/60\n","45000/45000 [==============================] - 15s 333us/sample - loss: 1.3487 - acc: 0.5185 - val_loss: 1.2216 - val_acc: 0.5594\n","Epoch 10/60\n","45000/45000 [==============================] - 15s 333us/sample - loss: 1.2850 - acc: 0.5458 - val_loss: 1.1484 - val_acc: 0.6072\n","Epoch 11/60\n","45000/45000 [==============================] - 15s 332us/sample - loss: 1.2291 - acc: 0.5696 - val_loss: 1.3867 - val_acc: 0.5358\n","Epoch 12/60\n","45000/45000 [==============================] - 15s 334us/sample - loss: 1.1703 - acc: 0.5950 - val_loss: 1.0200 - val_acc: 0.6452\n","Epoch 13/60\n","45000/45000 [==============================] - 15s 333us/sample - loss: 1.1177 - acc: 0.6104 - val_loss: 1.2506 - val_acc: 0.5578\n","Epoch 14/60\n","45000/45000 [==============================] - 15s 334us/sample - loss: 1.0649 - acc: 0.6319 - val_loss: 0.9565 - val_acc: 0.6702\n","Epoch 15/60\n","45000/45000 [==============================] - 15s 335us/sample - loss: 1.0088 - acc: 0.6523 - val_loss: 0.9891 - val_acc: 0.6644\n","Epoch 16/60\n","45000/45000 [==============================] - 15s 335us/sample - loss: 0.9612 - acc: 0.6700 - val_loss: 0.9932 - val_acc: 0.6562\n","Epoch 17/60\n","45000/45000 [==============================] - 15s 333us/sample - loss: 0.9049 - acc: 0.6907 - val_loss: 0.9697 - val_acc: 0.6684\n","Epoch 18/60\n","45000/45000 [==============================] - 15s 334us/sample - loss: 0.8584 - acc: 0.7086 - val_loss: 0.9604 - val_acc: 0.6776\n","Epoch 19/60\n","45000/45000 [==============================] - 15s 333us/sample - loss: 0.8144 - acc: 0.7244 - val_loss: 0.8134 - val_acc: 0.7220\n","Epoch 20/60\n","45000/45000 [==============================] - 15s 335us/sample - loss: 0.7699 - acc: 0.7383 - val_loss: 0.8813 - val_acc: 0.7094\n","Epoch 21/60\n","45000/45000 [==============================] - 15s 332us/sample - loss: 0.7258 - acc: 0.7556 - val_loss: 0.8493 - val_acc: 0.7204\n","Epoch 22/60\n","45000/45000 [==============================] - 15s 333us/sample - loss: 0.6697 - acc: 0.7733 - val_loss: 0.8596 - val_acc: 0.7194\n","Epoch 23/60\n","45000/45000 [==============================] - 15s 334us/sample - loss: 0.6367 - acc: 0.7844 - val_loss: 0.9009 - val_acc: 0.7128\n","Epoch 24/60\n","45000/45000 [==============================] - 15s 339us/sample - loss: 0.5985 - acc: 0.7995 - val_loss: 0.8200 - val_acc: 0.7340\n","Epoch 25/60\n","45000/45000 [==============================] - 15s 332us/sample - loss: 0.5558 - acc: 0.8115 - val_loss: 1.0086 - val_acc: 0.7116\n","Epoch 26/60\n","45000/45000 [==============================] - 15s 333us/sample - loss: 0.5150 - acc: 0.8253 - val_loss: 0.8285 - val_acc: 0.7422\n","Epoch 27/60\n","45000/45000 [==============================] - 15s 331us/sample - loss: 0.4851 - acc: 0.8363 - val_loss: 0.8528 - val_acc: 0.7466\n","Epoch 28/60\n","45000/45000 [==============================] - 15s 332us/sample - loss: 0.4514 - acc: 0.8470 - val_loss: 0.9183 - val_acc: 0.7290\n","Epoch 29/60\n","45000/45000 [==============================] - 15s 334us/sample - loss: 0.4166 - acc: 0.8606 - val_loss: 0.8955 - val_acc: 0.7444\n","10000/10000 [==============================] - 2s 153us/sample - loss: 0.8710 - acc: 0.7027\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.8709915576934815, 0.7027]"]},"metadata":{"tags":[]},"execution_count":6}]}]}