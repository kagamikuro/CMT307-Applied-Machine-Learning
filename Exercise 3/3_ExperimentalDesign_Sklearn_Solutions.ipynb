{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_ExperimentalDesign_Sklearn_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vPPsSia1Qpp",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOCEsdTf1YtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_test_split(dataset_full,ratio):\n",
        "  train_set=[]\n",
        "  test_set=[]\n",
        "  size_dataset_full=len(dataset_full)\n",
        "  size_test=int(round(size_dataset_full*ratio,0))\n",
        "  list_test_indices=random.sample(range(size_dataset_full), size_test)\n",
        "  for i,example in enumerate(dataset_full):\n",
        "    if i in list_test_indices: test_set.append(example)\n",
        "    else: train_set.append(example)\n",
        "  return train_set,test_set\n",
        "\n",
        "# To verify\n",
        "train_set_, test_set_=get_train_test_split(dataset_full,0.2)\n",
        "print (\"Size training set: \"+str(len(train_set_)))\n",
        "print (\"Size test set: \"+str(len(test_set_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPDTOlVp1a3o",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 2:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EDb9dm21dfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_num_features=[100,500,1000]\n",
        "best_f1_dev=0.0\n",
        "for num_features in list_num_features:\n",
        "  vocabulary=get_vocabulary(new_train_set, num_features)  \n",
        "  svm_clf=train_svm_classifier(new_train_set, vocabulary)\n",
        "  X_dev=[]\n",
        "  for instance in new_dev_set:\n",
        "    vector_instance=get_vector_text(vocabulary,instance[0])\n",
        "    X_dev.append(vector_instance)\n",
        "  X_dev=np.asarray(X_dev)\n",
        "  Y_dev_predictions=svm_clf.predict(X_dev)\n",
        "  f1_dev=f1_score(Y_dev_gold, Y_dev_predictions, average='macro')\n",
        "  print (\"F1-Score with \"+str(num_features)+\": \"+str(round(f1_dev,3)))\n",
        "  if f1_dev>=best_f1_dev:\n",
        "    best_f1_dev=f1_dev\n",
        "    best_num_features=num_features\n",
        "    best_vocabulary=vocabulary\n",
        "    best_svm_clf=svm_clf\n",
        "print (\"\\nBest F-Score overall in the dev set is \"+str(round(best_f1_dev,3))+\" with \"+str(best_num_features)+\" features.\")\n",
        "# Now we test the best classifier (in the dev set) on the test set\n",
        "X_test=[]\n",
        "Y_test=[]\n",
        "for instance in new_test_set:\n",
        "  vector_instance=get_vector_text(best_vocabulary,instance[0])\n",
        "  X_test.append(vector_instance)\n",
        "  Y_test.append(instance[1])\n",
        "Y_test_gold=np.asarray(Y_test)\n",
        "best_X_test=np.asarray(X_test)\n",
        "best_Y_text_predictions=best_svm_clf.predict(best_X_test)\n",
        "print(\"\\nPerformance in the test set\\n\")\n",
        "print(classification_report(Y_test_gold, best_Y_text_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGj9FA73Fr36",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 3:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oat-VJrKFqxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_folds=3\n",
        "num_features=1000\n",
        "kf = KFold(n_splits=num_folds)\n",
        "random.shuffle(dataset_full)\n",
        "kf.get_n_splits(dataset_full)\n",
        "j_fold=0\n",
        "accuracy_total=0.0\n",
        "for train_index, test_index in kf.split(dataset_full):\n",
        "  j_fold+=1\n",
        "  train_set_fold=[]\n",
        "  test_set_fold=[]\n",
        "  for i,instance in enumerate(dataset_full):\n",
        "    if i in train_index:\n",
        "      train_set_fold.append(instance)\n",
        "    else:\n",
        "      test_set_fold.append(instance)\n",
        "  vocabulary_fold=get_vocabulary(train_set_fold, num_features)\n",
        "  svm_clf_fold=train_svm_classifier(train_set_fold, vocabulary_fold)\n",
        "  X_test_fold=[]\n",
        "  Y_test_fold=[]\n",
        "  for instance in test_set_fold:\n",
        "    vector_instance=get_vector_text(vocabulary_fold,instance[0])\n",
        "    X_test_fold.append(vector_instance)\n",
        "    Y_test_fold.append(instance[1])\n",
        "  Y_test_fold_gold=np.asarray(Y_test_fold)\n",
        "  X_test_fold=np.asarray(X_test_fold)\n",
        "  Y_test_predictions_fold=svm_clf_fold.predict(X_test_fold)\n",
        "  accuracy_fold=accuracy_score(Y_test_fold_gold, Y_test_predictions_fold)\n",
        "  accuracy_total+=accuracy_fold\n",
        "  print (\"Fold \"+str(j_fold)+\"/\"+str(num_folds)+\" completed. Accuracy: \"+str(accuracy_fold))\n",
        "  \n",
        "average_accuracy=accuracy_total/num_folds\n",
        "print (\"\\nAverage Accuracy: \"+str(round(average_accuracy,3)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}