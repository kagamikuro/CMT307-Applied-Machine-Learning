{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "nav_menu": {
      "height": "309px",
      "width": "468px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "6_decision_trees.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4mu9dLKoAKA",
        "colab_type": "text"
      },
      "source": [
        "**Chapter 6 – Decision Trees**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_qmQAsuoAKG",
        "colab_type": "text"
      },
      "source": [
        "_This notebook is taken/adopted from Aurélien Géron's chapter 6._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lQECWExoAKJ",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrjvSJTsoAKM",
        "colab_type": "text"
      },
      "source": [
        "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8M2U2MaoAKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Z7GCCtoAKX",
        "colab_type": "text"
      },
      "source": [
        "# Training and visualizing\n",
        "This section illustrates the use of decision tree to classify Iris plant type based on flower measurements: sepal length, sepal width, petal length and petal width in cm. \n",
        "\n",
        "Note the data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant: Iris Setosa, Iris Versicolour and Iris Virginica.\n",
        "\n",
        "More information about Iris dataset can be found at https://archive.ics.uci.edu/ml/datasets/iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2elVpACoAKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris            # load iris data\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, 2:] # use only 2 features of petal length and width in this example, so we can visualise results in 2-d.\n",
        "y = iris.target\n",
        "\n",
        "# for how to use DecisionTreeClassifier, see https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)   # learn a tree with maximum depth of 3, use default values for other parameters\n",
        "tree_clf.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSlYKdOM7_9b",
        "colab_type": "text"
      },
      "source": [
        "Display the tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH23V47D7ExC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "tree.plot_tree(tree_clf, \n",
        "               feature_names=[\"Petal length\", \"Petal width\"], \n",
        "               class_names=['Setosa', 'Versicolour', 'Virginica'], \n",
        "               impurity=False, filled=True, rounded=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emBG0rLkN-ek",
        "colab_type": "text"
      },
      "source": [
        "Show decision boundary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJkKzssKoAKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
        "    x1s = np.linspace(axes[0], axes[1], 100)\n",
        "    x2s = np.linspace(axes[2], axes[3], 100)\n",
        "    x1, x2 = np.meshgrid(x1s, x2s)            # generate 100 x 100 data points in [0, 7.5] x [0, 3]\n",
        "    X_new = np.c_[x1.ravel(), x2.ravel()]     # re-arrange as 2-d data\n",
        "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
        "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
        "    if not iris:\n",
        "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
        "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
        "    if plot_training:\n",
        "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris-Setosa\")\n",
        "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris-Versicolor\")\n",
        "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris-Virginica\")\n",
        "        plt.axis(axes)\n",
        "    if iris:\n",
        "        plt.xlabel(\"Petal length\", fontsize=14)\n",
        "        plt.ylabel(\"Petal width\", fontsize=14)\n",
        "    else:\n",
        "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
        "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
        "    if legend:\n",
        "        plt.legend(loc=\"lower right\", fontsize=14)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_decision_boundary(tree_clf, X, y)\n",
        "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)\n",
        "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
        "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)\n",
        "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)\n",
        "plt.text(1.40, 1.0, \"Depth=0\", fontsize=15)\n",
        "plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n",
        "plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYWhxAGcHJrR",
        "colab_type": "text"
      },
      "source": [
        "# Exercise\n",
        "This exercise practices model hyperparameter selection/optimisation which is usually required in machine learning tasks.\n",
        "\n",
        "Change values of the following parameters of DecisionTreeClassifier to see how the learned tress differ:\n",
        "\n",
        "*   max_depth:          3, 4, default\n",
        "*   min_samples_split:  3, 4, 5, default\n",
        "*   min_samples_leaf:   2, 3, 4, default\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html for information about these parameters. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiAUP2NUoAK6",
        "colab_type": "text"
      },
      "source": [
        "# Predicting classes and class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wzkKQKOoAK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_clf.predict_proba([[5, 1.5]])        # predict the class probability of a data point [5, 1.5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMEsk3kCoALE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_clf.predict([[5, 1.5]])              # predict the class of a data point [5, 1.5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA9jpzOCoALL",
        "colab_type": "text"
      },
      "source": [
        "# Sensitivity to training set details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-awDDJO_Ci6T",
        "colab_type": "text"
      },
      "source": [
        "DT is **sensitive to small variations** in the training data. This code demonstrate this by removing the sample of the widest Iris-Versicolor from the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIx_SFIsoALN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1_max = X[(X[:, 1]==X[:, 1][y==1].max()) & (y==1)] # widest Iris-Versicolor flower\n",
        "x1_max[0][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nDJOLJ6oALU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#not_widest_versicolor = (X[:, 1]!=1.8) | (y==2)\n",
        "not_widest_versicolor = (X[:, 1] != x1_max[0][1]) | (y==2)\n",
        "X_tweaked = X[not_widest_versicolor]\n",
        "y_tweaked = y[not_widest_versicolor]\n",
        "\n",
        "tree_clf_tweaked = DecisionTreeClassifier(max_depth=2, random_state=40)\n",
        "tree_clf_tweaked.fit(X_tweaked, y_tweaked)\n",
        "tree.plot_tree(tree_clf_tweaked, \n",
        "               feature_names=[\"Petal length\", \"Petal width\"], \n",
        "               class_names=['Setosa', 'Versicolour', 'Virginica'], \n",
        "               impurity=False, filled=True, rounded=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0iIjNcFoALb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plot_decision_boundary(tree_clf_tweaked, X_tweaked, y_tweaked, legend=False)\n",
        "plt.plot([0, 7.5], [0.8, 0.8], \"k-\", linewidth=2)\n",
        "plt.plot([0, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
        "plt.text(1.0, 0.9, \"Depth=0\", fontsize=15)\n",
        "plt.text(1.0, 1.80, \"Depth=1\", fontsize=13)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI_YAKuFFgHE",
        "colab_type": "text"
      },
      "source": [
        "Another example on Moon data to demonstrate **regularization** using min_samples_leaf.\n",
        "\n",
        "This code learns 2 trees: one with default value, i.e., min_samples_leaf = 1, another with min_samples_leaf = 4. A larger value of min_samples_leaf regularises the growing of a tree to get a less complex tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EoEbbi3oALj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "Xm, ym = make_moons(n_samples=100, noise=0.25, random_state=53)\n",
        "\n",
        "# Two trees with different parameters for the minimum number of samples in leaf nodes, default=1\n",
        "deep_tree_clf1 = DecisionTreeClassifier(random_state=42)                        # tree 1, default min_samples_leaf=1, may overfitting\n",
        "deep_tree_clf2 = DecisionTreeClassifier(min_samples_leaf=4, random_state=42)    # tree 2\n",
        "deep_tree_clf1.fit(Xm, ym)\n",
        "deep_tree_clf2.fit(Xm, ym)\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.subplot(121)\n",
        "plot_decision_boundary(deep_tree_clf1, Xm, ym, axes=[-1.5, 2.5, -1, 1.5], iris=False)\n",
        "plt.title(\"No restrictions\", fontsize=16)\n",
        "plt.subplot(122)\n",
        "plot_decision_boundary(deep_tree_clf2, Xm, ym, axes=[-1.5, 2.5, -1, 1.5], iris=False)\n",
        "plt.title(\"min_samples_leaf = {}\".format(deep_tree_clf2.min_samples_leaf), fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZK6o7ZRHQnm",
        "colab_type": "text"
      },
      "source": [
        "A bit processing of Iris data by rotation.\n",
        "\n",
        "Rotate the Iris data by pi / 180 * 20, rotation matrix  ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAAAjCAYAAABM+o4SAAAE8klEQVRoBe1aPUgrQRCePFL6U8RCEQsjIlqI4g8KVsZCEUt/qlgIgiCoiGAnYmMRxVbSqE0Uywg2KiKCNkaxU0EF8QfUQmMp3ONb3i53SW4jbp63hzeQ5G5nb2/m+3ZmLrfrMwzDIE9ci8Af11ruGc4Q0I7Aq6sr6u/vJ5/PR0VFRbS1tfVrqPqO74zA09NTBhZAw2dhYcER0B4fH6mzs5NqamoomUzSysoKjY2NEdp1FdhWUVGhPNFkvg8ODjJewA3uZcbDEoHxeJxQEicnJx3Ba3p6mtra2mhmZoby8vKotLSU/H4/PT09OWLPV24K22AjbFURme+rq6uMF/CTKv7UBqfOkQWOj49pfX3dYkJhYSEVFxdb2nQ6qa+vp4uLCyWTVHy3RGAmK5CXh4eHM4YwdF1dXUKHfh8fH5ZhZmdnLekZ0Z3aBxfs7e1RWVkZVVZWiuvv7+/p9fVVnDt1YOcDT2285MAvjhVqN/Bpbm7OWpZUfJcSyPNyfn4+q0mJRIIaGxsJ55g1ra2t1NLSwnSoWdfX17S8vCxwhhNra2t0dHTEUkAsFqOXlxeWHkUnIkbo9vY27e7usrF5Le7p6aHy8nLWZu7/k8cyH+bn5ykYDFJVVRUzKRqN0tTUFIXDYdrf36eDgwM2MSORCMG/TBMXbSq+SwlEXgaAmIGoSUgXGxsb7HhpaYnq6upYvYSO16zz83OBL69hJycnrG1gYICQz1MF5N/c3BAcRQ3GB22hUIhFOMbOhQCsjo4OkTH4REn9RR8OtswH1L9AIEANDQ3MvImJCSopKSFkjufnZxoaGmK4ABOMk8kPVd9tCUT0HR4e0vj4eNqNuQ7pkxsFh2F4bW2twBqEg/zR0VGWSpBS7ARAtLe3CzX63t3dWdqE8psHsHVnZ0dMEj5ZUn/Rh/sl8wH+FhQUWDIEtxu4QTguvb29tlar+G5LoOzpiuvMgCNlnJ2dpQGOqLu9vaXq6moaGRkRM9vsDcZ7e3szNxEiHOkZADotdj5sbm6mZQiQ+vn5KR68QOj7+7uI0lRfVH23JRBPfjCEP2HBEBRoRB/XofhCoMP/te7ubgE4ageiD4LZbI5M1mj64uPhXpixuA7RjxrjpMh84JGF1IgnZ/SFgFT8FUIqhfAoRZqem5tLm8DKvuNdaCKRMAKBgBGPx3EqJBqNsnYiMpqamozLy0uhQ19cAx1+FxcXjWQyKfSxWEzoM10vOv47MI/X19dnuVdq3586z+ZDOBxmPgInCPwPhUJGJBIRJnK/gN/Dw4NoNx/wPsBJ5jv6BYNByzioB7YEmm/iHTuPQCYCbVMoi3/vS3sEPAK1p0huoEegHB/ttR6B2lMkN9AjUI6P9lqPQO0pkhuoFYF4IfBbVuNz5asygXgz879XpOVz0H1aYJarnQfKBPL3onilpCKyFWmVcXW8Npe+Kq/I42Uzf1/6XbBUVqS/e0+nrsu1r1+KQLxcxg4xvm7GV9V1WJHOFRH8ZT330bx5CDpddx5kJVD3FelcEMhrkht3HmQlUPcV6VwQ6OadB1kJ1H1FWpVARJ+bdx5kJRAA6bwirUqg7Cma63TeeWAhELvAUMT5NjlXrEgrMmheEcdQ/GEGkcl1Tu884A+L4CdNZMuUuq1Iy2xV0bl554EPjqex6jW4BgFLCnWN1Z6hAgGPQAGFOw88At3Jm7D6L7UkutrKVGz+AAAAAElFTkSuQmCC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKwF2SLHoALs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "angle = np.pi / 180 * 20\n",
        "rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
        "Xr = X.dot(rotation_matrix)\n",
        "\n",
        "tree_clf_r = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf_r.fit(Xr, y)\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plot_decision_boundary(tree_clf_r, Xr, y, axes=[0.5, 7.5, -1.0, 1], iris=False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIep64ysJ7TH",
        "colab_type": "text"
      },
      "source": [
        "One more example on the effect of **data orientation**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Mdgx1qoAL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(6)\n",
        "Xs = np.random.rand(100, 2) - 0.5           # generate a 2-d data in the range of [-0.5, 0.5]\n",
        "ys = (Xs[:, 0] > 0).astype(np.float32) * 2  # make it 2 classes\n",
        "\n",
        "angle = np.pi / 4                           # roate the data by 45 degree\n",
        "rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
        "Xsr = Xs.dot(rotation_matrix)\n",
        "\n",
        "tree_clf_s = DecisionTreeClassifier(random_state=42)    # classifier for the un-rotated data\n",
        "tree_clf_s.fit(Xs, ys)\n",
        "tree_clf_sr = DecisionTreeClassifier(random_state=42)   # classifier for the rotated data\n",
        "tree_clf_sr.fit(Xsr, ys)\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.subplot(121)\n",
        "plot_decision_boundary(tree_clf_s, Xs, ys, axes=[-0.7, 0.7, -0.7, 0.7], iris=False)\n",
        "plt.subplot(122)\n",
        "plot_decision_boundary(tree_clf_sr, Xsr, ys, axes=[-0.7, 0.7, -0.7, 0.7], iris=False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw2xEB4EoAL8",
        "colab_type": "text"
      },
      "source": [
        "# Regression trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPlOjgScoAL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quadratic training set + noise\n",
        "np.random.seed(42)\n",
        "m = 200\n",
        "X = np.random.rand(m, 1)\n",
        "y = 4 * (X - 0.5) ** 2\n",
        "y = y + np.random.randn(m, 1) / 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdsvwMEroAMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg.fit(X, y)\n",
        "tree.plot_tree(tree_reg, \n",
        "               feature_names=[\"X1\"], \n",
        "               filled=True, rounded=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gqMflINoAMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# learn 2 trees with different depth\n",
        "tree_reg1 = DecisionTreeRegressor(random_state=42, max_depth=2)\n",
        "tree_reg2 = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
        "tree_reg1.fit(X, y)\n",
        "tree_reg2.fit(X, y)\n",
        "\n",
        "def plot_regression_predictions(tree_reg, X, y, axes=[0, 1, -0.2, 1], ylabel=\"$y$\"):\n",
        "    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n",
        "    y_pred = tree_reg.predict(x1)\n",
        "    plt.axis(axes)\n",
        "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "    if ylabel:\n",
        "        plt.ylabel(ylabel, fontsize=18, rotation=0)\n",
        "    plt.plot(X, y, \"b.\")\n",
        "    plt.plot(x1, y_pred, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.subplot(121)\n",
        "plot_regression_predictions(tree_reg1, X, y)\n",
        "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
        "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
        "plt.text(0.21, 0.65, \"Depth=0\", fontsize=15)\n",
        "plt.text(0.01, 0.2, \"Depth=1\", fontsize=13)\n",
        "plt.text(0.65, 0.8, \"Depth=1\", fontsize=13)\n",
        "plt.legend(loc=\"upper center\", fontsize=18)\n",
        "plt.title(\"max_depth=2\", fontsize=14)\n",
        "\n",
        "plt.subplot(122)\n",
        "plot_regression_predictions(tree_reg2, X, y, ylabel=None)\n",
        "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
        "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
        "for split in (0.0458, 0.1298, 0.2873, 0.9040):\n",
        "    plt.plot([split, split], [-0.2, 1], \"k:\", linewidth=1)\n",
        "plt.text(0.3, 0.5, \"Depth=2\", fontsize=13)\n",
        "plt.title(\"max_depth=3\", fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdnvIrA_Ngqc",
        "colab_type": "text"
      },
      "source": [
        "Illustration of overfitting and regularisation\n",
        "\n",
        "Limit tree complexity using min_samples_leaf: 1 (default), 10 (a more regularised)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkY1zYm0oAMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_reg1 = DecisionTreeRegressor(random_state=42)    # default value for min_samples_leaf=1\n",
        "tree_reg2 = DecisionTreeRegressor(random_state=42, min_samples_leaf=10)\n",
        "tree_reg1.fit(X, y)\n",
        "tree_reg2.fit(X, y)\n",
        "\n",
        "x1 = np.linspace(0, 1, 500).reshape(-1, 1)\n",
        "y_pred1 = tree_reg1.predict(x1)\n",
        "y_pred2 = tree_reg2.predict(x1)\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.plot(x1, y_pred1, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
        "plt.axis([0, 1, -0.2, 1.1])\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", fontsize=18, rotation=0)\n",
        "plt.legend(loc=\"upper center\", fontsize=18)\n",
        "plt.title(\"No restrictions\", fontsize=14)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.plot(x1, y_pred2, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
        "plt.axis([0, 1, -0.2, 1.1])\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.title(\"min_samples_leaf={}\".format(tree_reg2.min_samples_leaf), fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}