{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f66c394feeea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#from models import alexnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#import alexnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "#from models import alexnet\n",
    "#import alexnet\n",
    "import tensorflow as tf\n",
    "import train_util as tu\n",
    "import numpy as np\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "\t\tepochs,\n",
    "\t\tbatch_size,\n",
    "\t\tlearning_rate,\n",
    "\t\tdropout,\n",
    "\t\tmomentum,\n",
    "\t\tlmbda,\n",
    "\t\tresume,\n",
    "\t\timagenet_path,\n",
    "\t\tdisplay_step,\n",
    "\t\ttest_step,\n",
    "\t\tckpt_path,\n",
    "\t\tsummary_path):\n",
    "\t\"\"\"\tProcedure to train the model on ImageNet ILSVRC 2012 training set\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tresume:\tboolean variable, true if want to resume the training, false to train from scratch\n",
    "\t\t\timagenet_path:\tpath to ILSRVC12 ImageNet folder containing train images,\n",
    "\t\t\t\t\t\tvalidation images, annotations and metadata file\n",
    "\t\t\tdisplay_step: number representing how often printing the current training accuracy\n",
    "\t\t\ttest_step: number representing how often make a test and print the validation accuracy\n",
    "\t\t\tckpt_path: path where to save model's tensorflow checkpoint (or from where resume)\n",
    "\t\t\tsummary_path: path where to save logs for TensorBoard\n",
    "\n",
    "\t\"\"\"\n",
    "\ttrain_img_path = os.path.join(imagenet_path, 'Data/CLS-LOC/train/')\n",
    "\tts_size = tu.imagenet_size(train_img_path)\n",
    "\tnum_batches = int(float(ts_size) / batch_size)\n",
    "\n",
    "\t#wnid_labels, _ = tu.load_imagenet_meta(os.path.join(imagenet_path, 'data/meta.mat'))\n",
    "\twnid_labels, _ = tu.load_imagenet_meta(os.path.join('ilsvrc_annot.txt'))\n",
    "\n",
    "\tx = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "\ty = tf.placeholder(tf.float32, [None, 1000])\n",
    "\n",
    "\tlr = tf.placeholder(tf.float32)\n",
    "\tkeep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\t# queue of examples being filled on the cpu\n",
    "\twith tf.device('/cpu:0'):\n",
    "\t\tq = tf.FIFOQueue(batch_size * 3, [tf.float32, tf.float32], shapes=[[224, 224, 3], [1000]])\n",
    "\t\tenqueue_op = q.enqueue_many([x, y])\n",
    "\n",
    "\t\tx_b, y_b = q.dequeue_many(batch_size)\n",
    "\n",
    "\tpred, _ = alexnet.classifier(x_b, keep_prob)\n",
    "\n",
    "\t# cross-entropy and weight decay\n",
    "\twith tf.name_scope('cross_entropy'):\n",
    "\t\tcross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_b, name='cross-entropy'))\n",
    "\n",
    "\twith tf.name_scope('l2_loss'):\n",
    "\t\tl2_loss = tf.reduce_sum(lmbda * tf.stack([tf.nn.l2_loss(v) for v in tf.get_collection('weights')]))\n",
    "\t\ttf.summary.scalar('l2_loss', l2_loss)\n",
    "\n",
    "\twith tf.name_scope('loss'):\n",
    "\t\tloss = cross_entropy + l2_loss\n",
    "\t\ttf.summary.scalar('loss', loss)\n",
    "\n",
    "\t# accuracy\n",
    "\twith tf.name_scope('accuracy'):\n",
    "\t\tcorrect = tf.equal(tf.argmax(pred, 1), tf.argmax(y_b, 1))\n",
    "\t\taccuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\t\ttf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "\tglobal_step = tf.Variable(0, trainable=False)\n",
    "\tepoch = tf.div(global_step, num_batches)\n",
    "\n",
    "\t# momentum optimizer\n",
    "\twith tf.name_scope('optimizer'):\n",
    "\t\toptimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=momentum).minimize(loss, global_step=global_step)\n",
    "\n",
    "\t# merge summaries to write them to file\n",
    "\tmerged = tf.summary.merge_all()\n",
    "\n",
    "\t# checkpoint saver\n",
    "\tsaver = tf.train.Saver()\n",
    "\n",
    "\tcoord = tf.train.Coordinator()\n",
    "\n",
    "\t#init = tf.initialize_all_variables()\n",
    "\tinit = tf.global_variables_initializer()\n",
    "\n",
    "\twith tf.Session(config=tf.ConfigProto()) as sess:\n",
    "\t\tif resume:\n",
    "\t\t\tsaver.restore(sess, os.path.join(ckpt_path, 'alexnet-cnn.ckpt'))\n",
    "\t\telse:\n",
    "\t\t\tsess.run(init)\n",
    "\n",
    "\t\t# enqueuing batches procedure\n",
    "\t\tdef enqueue_batches():\n",
    "\t\t\twhile not coord.should_stop():\n",
    "\t\t\t\tim, l = tu.read_batch(batch_size, train_img_path, wnid_labels)\n",
    "\t\t\t\tsess.run(enqueue_op, feed_dict={x: im,y: l})\n",
    "\n",
    "\t\t# creating and starting parallel threads to fill the queue\n",
    "\t\tnum_threads = 3\n",
    "\t\tfor i in range(num_threads):\n",
    "\t\t\tt = threading.Thread(target=enqueue_batches)\n",
    "\t\t\tt.setDaemon(True)\n",
    "\t\t\tt.start()\n",
    "\n",
    "\t\t# operation to write logs for tensorboard visualization\n",
    "\t\ttrain_writer = tf.summary.FileWriter(os.path.join(summary_path, 'train'), sess.graph)\n",
    "\n",
    "\t\tstart_time = time.time()\n",
    "\t\tfor e in range(sess.run(epoch), epochs):\n",
    "\t\t\tfor i in range(num_batches):\n",
    "\n",
    "\t\t\t\tsummary_str,_, step = sess.run([merged,optimizer, global_step], feed_dict={lr: learning_rate, keep_prob: dropout})\n",
    "\t\t\t\ttrain_writer.add_summary(summary_str, step)\n",
    "\n",
    "\t\t\t\t# decaying learning rate\n",
    "\t\t\t\tif step == 170000 or step == 350000:\n",
    "\t\t\t\t\tlearning_rate /= 10\n",
    "\n",
    "\t\t\t\t# display current training informations\n",
    "\t\t\t\tif step % display_step == 0:\n",
    "\t\t\t\t\tc, a = sess.run([loss, accuracy], feed_dict={lr: learning_rate, keep_prob: 1.0})\n",
    "\t\t\t\t\tprint ('Epoch: {:03d} Step/Batch: {:09d} --- Loss: {:.7f} Training accuracy: {:.4f}'.format(e, step, c, a))\n",
    "\n",
    "\t\t\t\t# make test and evaluate validation accuracy\n",
    "\t\t\t\tif step % test_step == 0:\n",
    "\t\t\t\t\tval_im, val_cls = tu.read_validation_batch(batch_size, os.path.join(imagenet_path, 'ILSVRC2012_img_val'), os.path.join(imagenet_path, 'data/ILSVRC2012_validation_ground_truth.txt'))\n",
    "\t\t\t\t\tv_a = sess.run(accuracy, feed_dict={x_b: val_im, y_b: val_cls, lr: learning_rate, keep_prob: 1.0})\n",
    "\t\t\t\t\t# intermediate time\n",
    "\t\t\t\t\tint_time = time.time()\n",
    "\t\t\t\t\tprint ('Elapsed time: {}'.format(tu.format_time(int_time - start_time)))\n",
    "\t\t\t\t\tprint ('Validation accuracy: {:.04f}'.format(v_a))\n",
    "\t\t\t\t\t# save weights to file\n",
    "\t\t\t\t\tsave_path = saver.save(sess, os.path.join(ckpt_path, 'alexnet-cnn.ckpt'))\n",
    "\t\t\t\t\tprint('Variables saved in file: %s' % save_path)\n",
    "\n",
    "\t\tend_time = time.time()\n",
    "\t\tprint ('Elapsed time: {}'.format(tu.format_time(end_time - start_time)))\n",
    "\t\tsave_path = saver.save(sess, os.path.join(ckpt_path, 'alexnet-cnn.ckpt'))\n",
    "\t\tprint('Variables saved in file: %s' % save_path)\n",
    "\n",
    "\t\tcoord.request_stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\tDROPOUT = 0.5\n",
    "\tMOMENTUM = 0.9\n",
    "\tLAMBDA = 5e-04 # for weight decay\n",
    "\tLEARNING_RATE = 1e-03\n",
    "\tEPOCHS = 90\n",
    "\tBATCH_SIZE = 128\n",
    "\tCKPT_PATH = 'ckpt-alexnet'\n",
    "\tif not os.path.exists(CKPT_PATH):\n",
    "\t\tos.makedirs(CKPT_PATH)\n",
    "\tSUMMARY = 'summary'\n",
    "\tif not os.path.exists(SUMMARY):\n",
    "\t\tos.makedirs(SUMMARY)\n",
    "\n",
    "\tIMAGENET_PATH = 'ILSVRC'\n",
    "\tDISPLAY_STEP = 10\n",
    "\tTEST_STEP = 500\n",
    "\n",
    "\tif sys.argv[1] == '-resume':\n",
    "\t\tresume = True\n",
    "\telif sys.argv[1] == '-scratch':\n",
    "\t\tresume = False\n",
    "\n",
    "\ttrain(\n",
    "\t\tEPOCHS,\n",
    "\t\tBATCH_SIZE,\n",
    "\t\tLEARNING_RATE,\n",
    "\t\tDROPOUT,\n",
    "\t\tMOMENTUM,\n",
    "\t\tLAMBDA,\n",
    "\t\tresume,\n",
    "\t\tIMAGENET_PATH,\n",
    "\t\tDISPLAY_STEP,\n",
    "\t\tTEST_STEP,\n",
    "\t\tCKPT_PATH,\n",
    "\t\tSUMMARY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
